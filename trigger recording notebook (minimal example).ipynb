{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119e71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import serial\n",
    "import datetime as dt\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from multiprocessing import Process, Queue, Event\n",
    "import glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "\n",
    "#if you want to display images as you record\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyk4a import *\n",
    "\n",
    "# imports from this module\n",
    "from top_bottom_triggered.fast_animate import *\n",
    "from top_bottom_triggered.commutator_utils import *\n",
    "from top_bottom_triggered.video_io import *\n",
    "from top_bottom_triggered.multicam_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10972938",
   "metadata": {},
   "source": [
    "# Known issues\n",
    "* Keyboard interrupt doesn't work on the main acquisition loop. No idea why.\n",
    "* If you prime the Azures, start the experiment, and then there's an error, in order to run the experiment again, you will need to:\n",
    "    * manually unfreeze the azures by sending a short pulse of triggers and then interrupting them (see cell beneath the data collection cell). This is just a quirk of how the Azures work; when you prime them to wait for a trigger, they will block until they receive a trigger, no exceptions! (If you put a timeout, they raise C errors which are hard to catch in Python.)\n",
    "    * re-create the Azure recording processes, and re-prime them (this is done for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b5baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce0da94a",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d218972",
   "metadata": {},
   "source": [
    "## Get mouse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c3ed78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gmou77', 'gmou83', 'gmou81', 'gmou78']\n"
     ]
    }
   ],
   "source": [
    "# generate a random order for mice to run, based on today's date \n",
    "# (will be the same even, eg, 1 hour later, as long as date is the same)\n",
    "\n",
    "mice_to_run = ['gmou77', 'gmou78', 'gmou81', 'gmou83']\n",
    "\n",
    "today = dt.datetime.now().date()\n",
    "date_hash = int(dt.datetime(today.year, today.month, today.day).timestamp())\n",
    "np.random.seed(date_hash)\n",
    "np.random.shuffle(mice_to_run)\n",
    "print(mice_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e3771",
   "metadata": {},
   "source": [
    "## File name + dir, expt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd03c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'test_minimal_example'\n",
    "time_in_minutes = 0.4 # go slightly longer than mkv to ensure complete overlap\n",
    "base_path = R'D:\\Jonah\\trigger_testing'\n",
    "# base_path = R'E:\\Jonah\\CeAMouse'\n",
    "file_suffix = ''  # disambiguate between two sessions on the same day\n",
    "date = dt.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61a5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path D:\\Jonah\\trigger_testing\\test_minimal_example\\20230523_test_minimal_example exists!\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(base_path, f'{subject}\\\\{date}_{subject}')\n",
    "# path = path.format(subject=subject, date=date)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print(f'Created {path}')\n",
    "else:\n",
    "    print(f'Path {path} exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c406fd",
   "metadata": {},
   "source": [
    "# Commutator Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e874b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "commutator_port = 'COM4'\n",
    "sync_device_port = 'COM7'\n",
    "\n",
    "with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "    ino.write('r'.encode('utf-8')) ## reset trigger counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bda8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_opto = False  # only set to true if there is a \"stim\" col in ino data\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6553eff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236633,117166,0\n",
      "Data has 3 elements\n"
     ]
    }
   ],
   "source": [
    "# test serial port and check dac value\n",
    "with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "    line = ino.readline().decode('utf-8').strip('\\r\\n')\n",
    "    print(line)\n",
    "    print(f'Data has {len(line.split(\",\"))} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8414f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "commutator_fname = f'{date}_{subject}{file_suffix}.txt'\n",
    "commutator_fullfile = os.path.join(path, commutator_fname)\n",
    "if exists(commutator_fullfile) and not overwrite:\n",
    "    raise ValueError(f'File {commutator_fullfile} exists! Add a suffix or change subject name.')\n",
    "elif exists(commutator_fullfile):\n",
    "    os.remove(commutator_fullfile)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30692eb3",
   "metadata": {},
   "source": [
    "# Azure setup\n",
    "Shouldn't really need to change this stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "positive-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File will be saved to: D:\\Jonah\\trigger_testing\\test_minimal_example\\20230523_test_minimal_example\\20230523_test_minimal_example.XYZ\n"
     ]
    }
   ],
   "source": [
    "# 'bottom': '000343492012',  # old bottom\n",
    "# 'bottom': '000693321712',  # new bottom\n",
    "\n",
    "# 000364192012  # old top\n",
    "# # new top\n",
    "serial_numbers = {\n",
    "    'bottom': '000693321712',\n",
    "    'top': '000500221712'\n",
    "}\n",
    "master = 'top'  # don't change (should be top)\n",
    "sync_delay,sync_delay_step = 0,500\n",
    "record_processes = {}\n",
    "\n",
    "file_prefix = os.path.join(path, f'{date}_{subject}' + file_suffix)\n",
    "print(f'File will be saved to: {file_prefix}.XYZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "simplified-hypothetical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:0\tSerial:000693321712\tColor:1.6.110\tDepth:1.6.80\r\n",
      "Index:1\tSerial:000500221712\tColor:1.6.110\tDepth:1.6.80\r\n",
      "{'bottom': 0, 'top': 1}\n"
     ]
    }
   ],
   "source": [
    "# If you get an error here, try unfreezing the azures; or just unplug + re-plug them. \n",
    "camera_indexes = get_camera_indexes(serial_numbers)\n",
    "print(camera_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50e897",
   "metadata": {},
   "source": [
    "## Prep the experiment!\n",
    "(Three priming cells, and then the DAQ cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebf3cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,data,trigger\n"
     ]
    }
   ],
   "source": [
    "# Get the header from the arduino, and save it to the file\n",
    "first_line = 1  # don't change\n",
    "second_line = 0  # don't change\n",
    "sync_sent = 0\n",
    "header_max_attempts = 10\n",
    "second_line_max_attempts = 10\n",
    "\n",
    "with open(commutator_fullfile, 'x') as file:\n",
    "    with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "        ino.write('r'.encode('utf-8')) ## reset trigger counter\n",
    "        reader = ReadLine(ino)\n",
    "        \n",
    "        # These checks get header and process it\n",
    "        if first_line:\n",
    "            # Ask the arduino to print the header\n",
    "            ino.write('h'.encode('utf-8'))\n",
    "\n",
    "            # Verify first line. First_line becomes false when good (ie, we're no longer on the first line)\n",
    "            status, first_line, second_line, header, n_attempts, read_lines = first_line_check(header_max_attempts, reader, file=file)\n",
    "            if not status:\n",
    "                raise RuntimeError('Didnt receive header!')\n",
    "            \n",
    "            trigger_idx = [i for i,val in enumerate(header.split(',')) if val=='trigger'][0]\n",
    "            header_len = len(header.split(','))\n",
    "            print(header)\n",
    "        \n",
    "        if second_line:\n",
    "            status, second_line = second_line_check(second_line_max_attempts, reader, header, n_good_thresh=10)\n",
    "        if not status:\n",
    "                raise RuntimeError('Number of csv''d datapoints doesnt match number of csv''d elements in header!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0eaf7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bottom': <Process name='Process-5' parent=12868 initial>,\n",
       " 'top': <Process name='Process-6' parent=12868 initial>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up azure processes\n",
    "\n",
    "interrupt_queues = {camera: Queue() for camera,ix in camera_indexes.items()}\n",
    "trigger_started_event = Event()\n",
    "for camera,ix in camera_indexes.items():\n",
    "    if camera==master:\n",
    "        k4a = PyK4A(Config(color_resolution=ColorResolution.OFF,  # RES_720P\n",
    "                           depth_mode=DepthMode.NFOV_UNBINNED,\n",
    "                           synchronized_images_only=False,\n",
    "                           wired_sync_mode=WiredSyncMode.SUBORDINATE), device_id=ix)\n",
    "        \n",
    "        p = Process(target=capture_from_azure, \n",
    "                    args=(k4a, file_prefix+'.'+camera, int(time_in_minutes*60)),\n",
    "                    kwargs={\n",
    "                        'display_time': True,\n",
    "                        'display_frames':True,\n",
    "                        'externally_triggered': True,\n",
    "                        'trigger_started_event': trigger_started_event,\n",
    "                        'interrupt_queue': interrupt_queues[camera]\n",
    "                    })\n",
    "        \n",
    "    else:\n",
    "        sync_delay += sync_delay_step\n",
    "        k4a = PyK4A(Config(color_resolution=ColorResolution.OFF,\n",
    "                           depth_mode=DepthMode.NFOV_UNBINNED,\n",
    "                           synchronized_images_only=False,\n",
    "                           wired_sync_mode=WiredSyncMode.SUBORDINATE,\n",
    "                           subordinate_delay_off_master_usec=sync_delay), device_id=ix)\n",
    "\n",
    "        p = Process(target=capture_from_azure, \n",
    "                    args=(k4a, file_prefix+'.'+camera, int(time_in_minutes*60)+5),\n",
    "                    kwargs={\n",
    "                        'display_time': camera==False,\n",
    "                        'externally_triggered': True,\n",
    "                        'interrupt_queue': interrupt_queues[camera]})\n",
    "\n",
    "    record_processes[camera] = p\n",
    "    \n",
    "record_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43f5a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azures primed...\n"
     ]
    }
   ],
   "source": [
    "# Start Azures   \n",
    "for camera in camera_indexes:\n",
    "    if camera != master:\n",
    "        record_processes[camera].start()\n",
    "time.sleep(3)\n",
    "record_processes[master].start()\n",
    "time.sleep(3)  # these sleep's are critical, st the Azure's are ready for the first trigger when it arrives\n",
    "print('Azures primed...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d7e00",
   "metadata": {},
   "source": [
    "#### Run this cell to start data acquisition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "190f0735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending start msg to sync device\n",
      "Sync device said: 1020 sync pulses started!\n",
      "\n",
      "Recording started well! Now we wait...\n",
      "joining az processes\n",
      "Done with main loop\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# timing vars\n",
    "start_time = dt.datetime.now()\n",
    "one_mindelta = dt.timedelta(minutes=1)\n",
    "exp_timedelta = time_in_minutes*one_mindelta # key var to be compared against (now - start_time)\n",
    "\n",
    "# Main DAQ loop\n",
    "try:\n",
    "    with open(commutator_fullfile, 'a') as file:\n",
    "        with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino, serial.Serial(sync_device_port, baudrate=9600, timeout=0.1) as sync_device:\n",
    "            \n",
    "            # More efficient serial reader\n",
    "            reader = ReadLine(ino)\n",
    "            \n",
    "            while (dt.datetime.now() - start_time) < exp_timedelta:  \n",
    "                \n",
    "                # Read the line\n",
    "                line = reader.readline().decode('utf-8').strip('\\r\\n')\n",
    "                \n",
    "                # Ensure trigger is starting at 0 (essential in order to align data later)\n",
    "                if not (sync_sent):\n",
    "                    assert int(line.split(',')[trigger_idx]) == 0\n",
    "                \n",
    "                # Remove the DEBUG output if present and debugging\n",
    "                if debug:\n",
    "                    line = line[:(line.find(',DEBUG:'))]    \n",
    "                    \n",
    "                # Assuming data looks good, start the sync device\n",
    "                if not(sync_sent) and not(first_line or second_line):\n",
    "                    print('sending start msg to sync device')\n",
    "                    num = b\"\".join([packIntAsLong(int(time_in_minutes*60*30 + 300))])\n",
    "                    sync_device.write(num)\n",
    "                    sync_sent = 1\n",
    "                    sync_response = sync_device.readline().decode(\"utf-8\")\n",
    "                    print(f'Sync device said: {sync_response}')\n",
    "                    if 'pulses started!' in sync_response: \n",
    "                        print('Recording started successfully! Now we wait...')\n",
    "                    else: raise RuntimeError('Got wrong response from sync device. Maybe try restarting it.')\n",
    "                        \n",
    "                # Check for the typical (but rare) serial read issues\n",
    "                if len(line) == 0:\n",
    "                    print('Got empty line, continuing...')\n",
    "                    continue\n",
    "                elif len(line.split(',')) != header_len:\n",
    "                    print('Got line with unexpected length (skipping):')\n",
    "                    print(line)\n",
    "                    continue\n",
    "                else:  \n",
    "                    # typical case -- write line directly to file\n",
    "                    file.write(line)\n",
    "                    file.write('\\n')\n",
    "            \n",
    "            # Join the Azure processes (ie block until they finish)\n",
    "            if trigger_started_event.is_set():\n",
    "                print('At end of recording. Joining az processes (may take a few moments...')\n",
    "                exit_codes = [p.join() for p in record_processes.values() if p.is_alive()]\n",
    "\n",
    "            print('Done with main loop')\n",
    "            \n",
    "# Catch unexpected errors            \n",
    "except:\n",
    "    print('Exception')\n",
    "    # Stop the Azures in the event of an interrupt\n",
    "    stop_azures(trigger_started_event, interrupt_queues, sync_device_port)\n",
    "    \n",
    "    raise\n",
    "    \n",
    "finally:\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a751d68",
   "metadata": {},
   "source": [
    "#### DEBUG\n",
    "* \"Cannot start process twice\" --> re-run the cell where you create the Azure processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3da94f",
   "metadata": {},
   "source": [
    "#### DEBUG: Unfreeze Azures\n",
    "Run this to send a short pulse of triggers via the syncing device to unfreeze the Azures, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d243ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 sync pulses started!\\r\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfreeze_azures(sync_device_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5dfa5",
   "metadata": {},
   "source": [
    "#### DEBUG: Stop Azures\n",
    "Run this to interrupt the Azures if they're running (eg because you unfroze them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62be4554",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interrupt_queues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m interrupt_queues\u001b[38;5;241m.\u001b[39mvalues(): q\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28mtuple\u001b[39m())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'interrupt_queues' is not defined"
     ]
    }
   ],
   "source": [
    "for q in interrupt_queues.values(): q.put(tuple())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badbe0e",
   "metadata": {},
   "source": [
    "## Post-experiment summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74083de2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(glob.glob(os.path.join(path, '*.txt'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74dd29a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therm over: 4608\n",
      "Therm under: 0\n",
      "Time elapsed since start: 66.8 minutes\n"
     ]
    }
   ],
   "source": [
    "therm_over_thresh_count = ((data.therm > 900) & (data.dac<=0.1)).sum()\n",
    "therm_under_thresh_count = ((data.therm < 200) & (data.dac >= 3.25)).sum()\n",
    "print(f'Therm over: {therm_over_thresh_count}')\n",
    "print(f'Therm under: {therm_under_thresh_count}')\n",
    "print(f'Time elapsed since start: {(dt.datetime.now() - start_time).seconds/60:0.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417facc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34247540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
