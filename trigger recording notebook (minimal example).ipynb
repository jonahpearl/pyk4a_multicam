{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119e71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import serial\n",
    "import datetime as dt\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from multiprocessing import Process, Queue, Event\n",
    "import glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "\n",
    "#if you want to display images as you record\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyk4a import *\n",
    "\n",
    "# imports from this module\n",
    "from top_bottom_triggered.fast_animate import *\n",
    "from top_bottom_triggered.commutator_utils import *\n",
    "from top_bottom_triggered.video_io import *\n",
    "from top_bottom_triggered.multicam_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbabea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrupt_sync_device(sync_device_port=None, sync_device=None):\n",
    "    if sync_device_port is not None and sync_device is not None:\n",
    "        raise ValueError('pass either port or device object')\n",
    "    elif sync_device_port is not None:\n",
    "        with serial.Serial(sync_device_port, baudrate=9600, timeout=0.1) as sync_device:\n",
    "            sync_device.write(b\"i\")\n",
    "            response = sync_device.readline().decode(\"utf-8\")\n",
    "    elif sync_device is not None:\n",
    "        sync_device.write(b\"i\")\n",
    "        response = sync_device.readline().decode(\"utf-8\")\n",
    "        \n",
    "    return response\n",
    "\n",
    "\n",
    "def unfreeze_azures(sync_device_port=None, sync_device=None):\n",
    "    \"\"\"Send a short burst of triggers to the azures\n",
    "    \"\"\"\n",
    "    num = b\"\".join([packIntAsLong(int(5))])\n",
    "    if sync_device_port is not None and sync_device is not None:\n",
    "        raise ValueError('pass either port or device object')\n",
    "    elif sync_device_port is not None:\n",
    "        with serial.Serial(sync_device_port, baudrate=9600, timeout=0.1) as sync_device:\n",
    "            sync_device.write(num)\n",
    "            response = sync_device.readline().decode(\"utf-8\")\n",
    "    elif sync_device is not None:\n",
    "        sync_device.write(num)\n",
    "        response = sync_device.readline().decode(\"utf-8\")\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bbc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f96429",
   "metadata": {},
   "source": [
    "# Known issues\n",
    "* Keyboard interrupt doesn't work on the main acquisition loop. No idea why.\n",
    "* Putting the Azure priming step into the same cell as the main acquisition loop doesnt work very well. Easier to separate it, as it currently is. \n",
    "* If you prime the Azures, start the experiment, and then there's an error, in order to run the experiment again, you will need to:\n",
    "    * manually unfreeze the azures by sending a short pulse of triggers and then interrupting them (see cell beneath the data collection cell). This is just a quirk of how the Azures work; when you prime them to wait for a trigger, they will block until they receive a trigger, no exceptions! (If you put a timeout, they raise C errors which are hard to catch in Python.)\n",
    "    * re-create the Azure recording processes, because each `multiprocessing` process can only be started once.\n",
    "    * re-prime the Azures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a088d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce0da94a",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d218972",
   "metadata": {},
   "source": [
    "## Get mouse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c3ed78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gmou78', 'gmou83', 'gmou81', 'gmou77']\n"
     ]
    }
   ],
   "source": [
    "# generate a random order for mice to run, based on today's date \n",
    "# (will be the same even, eg, 1 hour later, as long as date is the same)\n",
    "\n",
    "mice_to_run = ['gmou77', 'gmou78', 'gmou81', 'gmou83']\n",
    "\n",
    "today = dt.datetime.now().date()\n",
    "date_hash = int(dt.datetime(today.year, today.month, today.day).timestamp())\n",
    "np.random.seed(date_hash)\n",
    "np.random.shuffle(mice_to_run)\n",
    "print(mice_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e3771",
   "metadata": {},
   "source": [
    "## File name + dir, expt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd03c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'test_minimal_example'\n",
    "time_in_minutes = 10 # go slightly longer than mkv to ensure complete overlap\n",
    "base_path = R'D:\\Jonah\\trigger_testing'\n",
    "# base_path = R'E:\\Jonah\\CeAMouse'\n",
    "file_suffix = ''  # disambiguate between two sessions on the same day\n",
    "date = dt.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61a5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created D:\\Jonah\\trigger_testing\\test_minimal_example\\20230428_test_minimal_example\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(base_path, f'{subject}\\\\{date}_{subject}')\n",
    "# path = path.format(subject=subject, date=date)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print(f'Created {path}')\n",
    "else:\n",
    "    print(f'Path {path} exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c406fd",
   "metadata": {},
   "source": [
    "# Commutator Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e874b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "commutator_port = 'COM4'\n",
    "sync_device_port = 'COM7'\n",
    "\n",
    "with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "    ino.write('r'.encode('utf-8')) ## reset trigger counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bda8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_opto = False  # only set to true if there is a \"stim\" col in ino data\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6553eff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116141,56920,0\n",
      "Data has 3 elements\n"
     ]
    }
   ],
   "source": [
    "# test serial port and check dac value\n",
    "with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "    line = ino.readline().decode('utf-8').strip('\\r\\n')\n",
    "    print(line)\n",
    "    print(f'Data has {len(line.split(\",\"))} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8414f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded params -- don't chage\n",
    "n_samples = 4000  # how many thermistor samples to show\n",
    "q_downsample = 15  # leave at 15; how much to downsample rt output (doesnt affect saved data) (eg if 20, and ino at 1 khz, will be 50 hz)\n",
    "fs = 500  # fs of the commutator teensy\n",
    "commutator_fname = f'{date}_{subject}{file_suffix}.txt'\n",
    "commutator_fullfile = os.path.join(path, commutator_fname)\n",
    "if exists(commutator_fullfile) and not overwrite:\n",
    "    raise ValueError(f'File {commutator_fullfile} exists! Add a suffix or change subject name.')\n",
    "elif exists(commutator_fullfile):\n",
    "    os.remove(commutator_fullfile)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30692eb3",
   "metadata": {},
   "source": [
    "# Azure setup\n",
    "Shouldn't really need to change this stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "positive-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File will be saved to: D:\\Jonah\\trigger_testing\\test_minimal_example\\20230428_test_minimal_example\\20230428_test_minimal_example.XYZ\n"
     ]
    }
   ],
   "source": [
    "# 'bottom': '000343492012',  # old bottom\n",
    "# 'bottom': '000693321712',  # new bottom\n",
    "\n",
    "# 000364192012  # old top\n",
    "# # new top\n",
    "serial_numbers = {\n",
    "    'bottom': '000693321712',\n",
    "    'top': '000500221712'\n",
    "}\n",
    "master = 'top'  # don't change (should be top)\n",
    "sync_delay,sync_delay_step = 0,500\n",
    "record_processes = {}\n",
    "\n",
    "file_prefix = os.path.join(path, f'{date}_{subject}' + file_suffix)\n",
    "print(f'File will be saved to: {file_prefix}.XYZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "simplified-hypothetical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:0\tSerial:000693321712\tColor:1.6.110\tDepth:1.6.80\r\n",
      "Index:1\tSerial:000500221712\tColor:1.6.110\tDepth:1.6.80\r\n",
      "{'bottom': 0, 'top': 1}\n"
     ]
    }
   ],
   "source": [
    "# If you get an error here, try unfreezing the azures; or just unplug + re-plug them. \n",
    "camera_indexes = get_camera_indexes(serial_numbers)\n",
    "print(camera_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66b189e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bottom': <Process name='Process-5' parent=15648 initial>,\n",
       " 'top': <Process name='Process-6' parent=15648 initial>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interrupt_queues = {camera: Queue() for camera,ix in camera_indexes.items()}\n",
    "trigger_started_event = Event()\n",
    "for camera,ix in camera_indexes.items():\n",
    "    if camera==master:\n",
    "        k4a = PyK4A(Config(color_resolution=ColorResolution.OFF,  # RES_720P\n",
    "                           depth_mode=DepthMode.NFOV_UNBINNED,\n",
    "                           synchronized_images_only=False,\n",
    "                           wired_sync_mode=WiredSyncMode.SUBORDINATE), device_id=ix)\n",
    "        \n",
    "        p = Process(target=capture_from_azure, \n",
    "                    args=(k4a, file_prefix+'.'+camera, int(time_in_minutes*60)),\n",
    "                    kwargs={\n",
    "                        'display_time': True,\n",
    "                        'display_frames':True,\n",
    "                        'externally_triggered': True,\n",
    "                        'trigger_started_event': trigger_started_event,\n",
    "                        'interrupt_queue': interrupt_queues[camera]\n",
    "                    })\n",
    "        \n",
    "    else:\n",
    "        sync_delay += sync_delay_step\n",
    "        k4a = PyK4A(Config(color_resolution=ColorResolution.OFF,\n",
    "                           depth_mode=DepthMode.NFOV_UNBINNED,\n",
    "                           synchronized_images_only=False,\n",
    "                           wired_sync_mode=WiredSyncMode.SUBORDINATE,\n",
    "                           subordinate_delay_off_master_usec=sync_delay), device_id=ix)\n",
    "\n",
    "        p = Process(target=capture_from_azure, \n",
    "                    args=(k4a, file_prefix+'.'+camera, int(time_in_minutes*60)+5),\n",
    "                    kwargs={\n",
    "                        'display_time': camera==False,\n",
    "                        'externally_triggered': True,\n",
    "                        'interrupt_queue': interrupt_queues[camera]})\n",
    "\n",
    "    record_processes[camera] = p\n",
    "    \n",
    "record_processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50e897",
   "metadata": {},
   "source": [
    "## Run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebf3cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,data,trigger\n"
     ]
    }
   ],
   "source": [
    "# Get the header from the arduino, and save it to the file\n",
    "first_line = 1  # don't change\n",
    "second_line = 0  # don't change\n",
    "sync_sent = 0\n",
    "header_max_attempts = 10\n",
    "second_line_max_attempts = 10\n",
    "\n",
    "with open(commutator_fullfile, 'x') as file:\n",
    "    with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "        ino.write('r'.encode('utf-8')) ## reset trigger counter\n",
    "        reader = ReadLine(ino)\n",
    "        \n",
    "        # These checks get header and process it\n",
    "        if first_line:\n",
    "            # Ask the arduino to print the header\n",
    "            ino.write('h'.encode('utf-8'))\n",
    "\n",
    "            # Verify first line. First_line becomes false when good (ie, we're no longer on the first line)\n",
    "            status, first_line, second_line, header, n_attempts, read_lines = first_line_check(header_max_attempts, reader, file=file)\n",
    "            if not status:\n",
    "                raise RuntimeError('Didnt receive header!')\n",
    "            \n",
    "            trigger_idx = [i for i,val in enumerate(header.split(',')) if val=='trigger'][0]\n",
    "            header_len = len(header.split(','))\n",
    "            print(header)\n",
    "        \n",
    "        if second_line:\n",
    "            status, second_line = second_line_check(second_line_max_attempts, reader, header, n_good_thresh=10)\n",
    "        if not status:\n",
    "                raise RuntimeError('Number of csv''d datapoints doesnt match number of csv''d elements in header!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43f5a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azures primed...\n"
     ]
    }
   ],
   "source": [
    "# Start Azures   \n",
    "for camera in camera_indexes:\n",
    "    if camera != master:\n",
    "        record_processes[camera].start()\n",
    "time.sleep(5)\n",
    "record_processes[master].start()\n",
    "print('Azures primed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f0735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending start msg to sync device\n",
      "Sync device said: 18300 sync pulses started!\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# timing vars\n",
    "start_time = dt.datetime.now()\n",
    "one_mindelta = dt.timedelta(minutes=1)\n",
    "exp_timedelta = time_in_minutes*one_mindelta # key var to be compared against (now - start_time)\n",
    "\n",
    "# Main DAQ loop\n",
    "try:\n",
    "    with open(commutator_fullfile, 'a') as file:\n",
    "        with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino, serial.Serial(sync_device_port, baudrate=9600, timeout=0.1) as sync_device:\n",
    "            \n",
    "            # More efficient serial reader\n",
    "            reader = ReadLine(ino)\n",
    "            \n",
    "            while (dt.datetime.now() - start_time) < exp_timedelta:  \n",
    "                \n",
    "                # Read the line\n",
    "                line = reader.readline().decode('utf-8').strip('\\r\\n')\n",
    "                \n",
    "                # Ensure trigger is starting at 0 (essential in order to align data later)\n",
    "                if not (sync_sent):\n",
    "                    assert int(line.split(',')[trigger_idx]) == 0\n",
    "                \n",
    "                # Remove the DEBUG output if present and debugging\n",
    "                if debug:\n",
    "                    line = line[:(line.find(',DEBUG:'))]    \n",
    "                    \n",
    "                # Assuming data looks good, start the sync device\n",
    "                if not(sync_sent) and not(first_line or second_line):\n",
    "                    print('sending start msg to sync device')\n",
    "                    num = b\"\".join([packIntAsLong(int(time_in_minutes*60*30 + 300))])\n",
    "                    sync_device.write(num)\n",
    "                    sync_sent = 1\n",
    "                    print(f'Sync device said: {sync_device.readline().decode(\"utf-8\")}')\n",
    "                    \n",
    "                # Check for the typical (but rare) serial read issues\n",
    "                if len(line) == 0:\n",
    "                    print('Got empty line, continuing...')\n",
    "                    continue\n",
    "                elif len(line.split(',')) != header_len:\n",
    "                    print('Got line with unexpected length (skipping):')\n",
    "                    print(line)\n",
    "                    continue\n",
    "                else:  \n",
    "                    # typical case -- write line directly to file\n",
    "                    file.write(line)\n",
    "                    file.write('\\n')\n",
    "            \n",
    "            # Join the Azure processes (ie block until they finish)\n",
    "            if trigger_started_event.is_set():\n",
    "                print('joining az processes')\n",
    "                exit_codes = [p.join() for p in record_processes.values() if p.is_alive()]\n",
    "\n",
    "            print('Done with main loop')\n",
    "            \n",
    "# Catch unexpected errors            \n",
    "except:\n",
    "    print('Exception')\n",
    "    # Stop the Azures in the event of an interrupt\n",
    "    if trigger_started_event.is_set():\n",
    "        print('halting azures')\n",
    "        for q in interrupt_queues.values(): q.put(tuple())\n",
    "        \n",
    "        # Stop the syncing device in the event of an interrupt\n",
    "        print('Stopping sync device')\n",
    "        response = interrupt_sync_device(sync_device_port)\n",
    "    else:\n",
    "        print('unfreezing azures (might not work here! unclear why)')\n",
    "        response = unfreeze_azures(sync_device_port=sync_device_port)\n",
    "        print(f\"Sync device said: {response}\")\n",
    "        for q in interrupt_queues.values(): q.put(tuple())\n",
    "    \n",
    "    raise\n",
    "    \n",
    "finally:\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c51c03ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this to send a short pulse of triggers to unfreeze the Azures, if necessary\n",
    "unfreeze_azures(sync_device_port)\n",
    "for q in interrupt_queues.values(): q.put(tuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1abc0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3badbe0e",
   "metadata": {},
   "source": [
    "## Post-experiment summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74083de2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(glob.glob(os.path.join(path, '*.txt'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74dd29a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therm over: 4608\n",
      "Therm under: 0\n",
      "Time elapsed since start: 66.8 minutes\n"
     ]
    }
   ],
   "source": [
    "therm_over_thresh_count = ((data.therm > 900) & (data.dac<=0.1)).sum()\n",
    "therm_under_thresh_count = ((data.therm < 200) & (data.dac >= 3.25)).sum()\n",
    "print(f'Therm over: {therm_over_thresh_count}')\n",
    "print(f'Therm under: {therm_under_thresh_count}')\n",
    "print(f'Time elapsed since start: {(dt.datetime.now() - start_time).seconds/60:0.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417facc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34247540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
