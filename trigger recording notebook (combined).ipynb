{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119e71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import serial\n",
    "import datetime as dt\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from multiprocessing import Process, Queue, Event\n",
    "import glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "\n",
    "#if you want to display images as you record\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyk4a import *\n",
    "\n",
    "# imports from this module\n",
    "from top_bottom_triggered.fast_animate import *\n",
    "from top_bottom_triggered.commutator_utils import *\n",
    "from top_bottom_triggered.video_io import *\n",
    "from top_bottom_triggered.multicam_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fa297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bc2afef",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afda94b",
   "metadata": {},
   "source": [
    "## Get mouse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c3ed78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gmou77', 'gmou83', 'gmou81', 'gmou78']\n"
     ]
    }
   ],
   "source": [
    "# generate a random order for mice to run, based on today's date \n",
    "# (will be the same even, eg, 1 hour later, as long as date is the same)\n",
    "\n",
    "mice_to_run = ['gmou77', 'gmou78', 'gmou81', 'gmou83']\n",
    "\n",
    "today = dt.datetime.now().date()\n",
    "date_hash = int(dt.datetime(today.year, today.month, today.day).timestamp())\n",
    "np.random.seed(date_hash)\n",
    "np.random.shuffle(mice_to_run)\n",
    "print(mice_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bd7ba",
   "metadata": {},
   "source": [
    "## File name + dir, expt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acd1015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subject = 'tmp'\n",
    "time_in_minutes = 0.5 # slightly longer than mkv to ensure complete overlap\n",
    "base_path = R'D:\\Jonah\\Thermistor_recordings'\n",
    "# base_path = R'E:\\Jonah\\CeAMouse'\n",
    "file_suffix = ''  # disambiguate between two sessions on the same day\n",
    "date = dt.datetime.now().strftime('%Y%m%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4da5004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path D:\\Jonah\\Thermistor_recordings\\tmp\\20230523_tmp exists!\n"
     ]
    }
   ],
   "source": [
    "overwrite = False\n",
    "path = os.path.join(base_path, f'{subject}\\\\{date}_{subject}')\n",
    "# path = path.format(subject=subject, date=date)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print(f'Created {path}')\n",
    "else:\n",
    "    print(f'Path {path} exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c406fd",
   "metadata": {},
   "source": [
    "# Commutator Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e874b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "commutator_port = 'COM4'\n",
    "sync_device_port = 'COM7'\n",
    "\n",
    "with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "    ino.write('r'.encode('utf-8')) ## reset trigger counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12bda8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_opto = False  # only set to true if there is a \"stim\" col in ino data\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6553eff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307.3750,-25.6250,20.1875,0.05,-0.11,-0.05,0,3.30,0\n",
      "Data has 9 elements\n"
     ]
    }
   ],
   "source": [
    "# test serial port and check dac value\n",
    "with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "    line = ino.readline().decode('utf-8').strip('\\r\\n')\n",
    "    print(line)\n",
    "    print(f'Data has {len(line.split(\",\"))} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497a5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded params -- don't chage\n",
    "n_samples = 4000  # how many thermistor samples to show\n",
    "q_downsample = 15  # leave at 15; how much to downsample rt output (doesnt affect saved data) (eg if 20, and ino at 1 khz, will be 50 hz)\n",
    "fs = 500  # fs of the commutator teensy\n",
    "commutator_fname = f'{date}_{subject}{file_suffix}.txt'\n",
    "commutator_fullfile = os.path.join(path, commutator_fname)\n",
    "if exists(commutator_fullfile) and not overwrite:\n",
    "    raise ValueError(f'File {commutator_fullfile} exists! Add a suffix or change subject name.')\n",
    "elif exists(commutator_fullfile):\n",
    "    os.remove(commutator_fullfile)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb52fa65",
   "metadata": {},
   "source": [
    "# Azure setup\n",
    "Shouldn't really need to change this stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "positive-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File will be saved to: D:\\Jonah\\Thermistor_recordings\\tmp\\20230523_tmp\\20230523_tmp.XYZ\n"
     ]
    }
   ],
   "source": [
    "# 'bottom': '000343492012',  # old bottom\n",
    "# 'bottom': '000693321712',  # new bottom\n",
    "\n",
    "# 000364192012  # old top\n",
    "# # new top\n",
    "serial_numbers = {\n",
    "    'bottom': '000693321712',\n",
    "    'top': '000500221712'\n",
    "}\n",
    "master = 'top'  # don't change (should be top)\n",
    "sync_delay,sync_delay_step = 0,500\n",
    "record_processes = {}\n",
    "\n",
    "file_prefix = os.path.join(path, f'{date}_{subject}' + file_suffix)\n",
    "print(f'File will be saved to: {file_prefix}.XYZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simplified-hypothetical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:0\tSerial:000693321712\tColor:1.6.110\tDepth:1.6.80\r\n",
      "Index:1\tSerial:000500221712\tColor:1.6.110\tDepth:1.6.80\r\n",
      "{'bottom': 0, 'top': 1}\n"
     ]
    }
   ],
   "source": [
    "# If you get an error here, try unfreezing the azures; or just unplug + re-plug them. \n",
    "camera_indexes = get_camera_indexes(serial_numbers)\n",
    "print(camera_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50e897",
   "metadata": {},
   "source": [
    "## Prep the experiment!\n",
    "(Three priming cells, and then the DAQ cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d2532f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,led1,led2,led3,led4,yaw,roll,pitch,acc_x,acc_y,acc_z,therm,dac,trigger\n",
      "Header looks good!\n"
     ]
    }
   ],
   "source": [
    "# Get the header from the arduino, and save it to the file\n",
    "first_line = 1  # don't change\n",
    "second_line = 0  # don't change\n",
    "sync_sent = 0\n",
    "header_max_attempts = 10\n",
    "second_line_max_attempts = 10\n",
    "\n",
    "# Open queue to animator\n",
    "thermistor_animator = ThermistorAnimator(n_samples, 500, show_opto=show_opto)\n",
    "\n",
    "with open(commutator_fullfile, 'x') as file:\n",
    "    with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino:\n",
    "        ino.write('r'.encode('utf-8')) ## reset trigger counter\n",
    "        reader = ReadLine(ino)\n",
    "        \n",
    "        # These checks get header and process it\n",
    "        if first_line:\n",
    "            # Ask the arduino to print the header\n",
    "            ino.write('h'.encode('utf-8'))\n",
    "\n",
    "            # Verify first line. First_line becomes false when good (ie, we're no longer on the first line)\n",
    "            status, first_line, second_line, header, n_attempts, read_lines = first_line_check(header_max_attempts, reader, file=file)\n",
    "            if not status:\n",
    "                raise RuntimeError('Didnt receive header!')\n",
    "\n",
    "            # Extract indices of values we're intersted in\n",
    "            header_len = len(header.split(','))\n",
    "            print(header)\n",
    "            thermistor_animator.extract_indices_from_header(header)\n",
    "            trigger_idx = [i for i,val in enumerate(header.split(',')) if val=='trigger'][0]\n",
    "        \n",
    "        if second_line:\n",
    "            status, second_line = second_line_check(second_line_max_attempts, reader, header, n_good_thresh=10)\n",
    "        if not status:\n",
    "                raise RuntimeError('Number of csv''d datapoints doesnt match number of csv''d elements in header!') \n",
    "                \n",
    "print('Header looks good!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8ca6c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bottom': <Process name='Process-12' parent=488 initial>,\n",
       " 'top': <Process name='Process-13' parent=488 initial>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interrupt_queues = {camera: Queue() for camera,ix in camera_indexes.items()}\n",
    "trigger_started_event = Event()\n",
    "for camera,ix in camera_indexes.items():\n",
    "    if camera==master:\n",
    "        k4a = PyK4A(Config(color_resolution=ColorResolution.OFF,  # RES_720P\n",
    "                           depth_mode=DepthMode.NFOV_UNBINNED,\n",
    "                           synchronized_images_only=False,\n",
    "                           wired_sync_mode=WiredSyncMode.SUBORDINATE), device_id=ix)\n",
    "        \n",
    "        p = Process(target=capture_from_azure, \n",
    "                    args=(k4a, file_prefix+'.'+camera, int((time_in_minutes-0.1)*60)),\n",
    "                    kwargs={\n",
    "                        'display_time': True,\n",
    "                        'display_frames':True,\n",
    "                        'externally_triggered': True,\n",
    "                        'trigger_started_event': trigger_started_event,\n",
    "                        'interrupt_queue': interrupt_queues[camera]\n",
    "                    })\n",
    "        \n",
    "    else:\n",
    "        sync_delay += sync_delay_step\n",
    "        k4a = PyK4A(Config(color_resolution=ColorResolution.OFF,\n",
    "                           depth_mode=DepthMode.NFOV_UNBINNED,\n",
    "                           synchronized_images_only=False,\n",
    "                           wired_sync_mode=WiredSyncMode.SUBORDINATE,\n",
    "                           subordinate_delay_off_master_usec=sync_delay), device_id=ix)\n",
    "\n",
    "        p = Process(target=capture_from_azure, \n",
    "                    args=(k4a, file_prefix+'.'+camera, int((time_in_minutes-0.1)*60)+5),\n",
    "                    kwargs={\n",
    "                        'display_time': camera==False,\n",
    "                        'externally_triggered': True,\n",
    "                        'interrupt_queue': interrupt_queues[camera]})\n",
    "\n",
    "    record_processes[camera] = p\n",
    "    \n",
    "record_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f02752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azures primed...\n"
     ]
    }
   ],
   "source": [
    "# Start Azures   \n",
    "for camera in camera_indexes:\n",
    "    if camera != master:\n",
    "        record_processes[camera].start()\n",
    "time.sleep(3)\n",
    "record_processes[master].start()\n",
    "time.sleep(3)  # these sleep's are critical, st the Azure's are ready for the first trigger when it arrives\n",
    "print('Azures primed...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d7e00",
   "metadata": {},
   "source": [
    "#### Run this cell to start data acquisition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "190f0735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending start msg to sync device\n",
      "Sync device said: 1200 sync pulses started!\n",
      "\n",
      "Exception\n",
      "halting azures\n",
      "Stopping sync device\n",
      "Stopping animator\n",
      "Done.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "test",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     thermistor_animator\u001b[38;5;241m.\u001b[39mupdate(line)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trigger_started_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m---> 57\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# After data collection finishes, close animator queue\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosing animator queue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: test"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\queues.py\", line 241, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 290, in _send_bytes\n",
      "    nwritten, err = ov.GetOverlappedResult(True)\n",
      "BrokenPipeError: [WinError 109] The pipe has been ended\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\queues.py\", line 241, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\queues.py\", line 241, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\queues.py\", line 241, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\queues.py\", line 241, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\queues.py\", line 241, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\dattalab\\anaconda3\\envs\\pyk4a\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n"
     ]
    }
   ],
   "source": [
    "# timing vars\n",
    "start_time = dt.datetime.now()\n",
    "one_mindelta = dt.timedelta(minutes=1)\n",
    "exp_timedelta = time_in_minutes*one_mindelta # key var to be compared against (now - start_time)\n",
    "\n",
    "\n",
    "# Main DAQ loop\n",
    "try:\n",
    "    with open(commutator_fullfile, 'a') as file:\n",
    "        with serial.Serial(commutator_port, baudrate=115200, timeout=0.1) as ino, serial.Serial(sync_device_port, baudrate=9600, timeout=0.1) as sync_device:\n",
    "            \n",
    "            # Create more efficient serial reader\n",
    "            reader = ReadLine(ino)\n",
    "\n",
    "            # Start thermistor animator\n",
    "            thermistor_animator.start()\n",
    "            \n",
    "            # Run the experiment for the requested amt of time!\n",
    "            while (dt.datetime.now() - start_time) < exp_timedelta:  \n",
    "                \n",
    "                # Read the current line of data\n",
    "                line = reader.readline().decode('utf-8').strip('\\r\\n')\n",
    "                \n",
    "                # Remove the DEBUG output if present and debugging\n",
    "                if debug:\n",
    "                    line = line[:(line.find(',DEBUG:'))]  \n",
    "                    \n",
    "                # Check for the typical (but relatively infrequent) serial read issues\n",
    "                if len(line) == 0:\n",
    "                    print('Got empty line, continuing...')\n",
    "                    continue\n",
    "                elif len(line.split(',')) != header_len:\n",
    "                    print('Got line with unexpected length (skipping):')\n",
    "                    print(line)\n",
    "                    continue\n",
    "                    \n",
    "                # Once, at the beginning, double check the trigger counter is starting at 0\n",
    "                if not (sync_sent):\n",
    "                    assert int(line.split(',')[trigger_idx]) == 0\n",
    "                    \n",
    "                # Once, assuming data looks good, start the sync device\n",
    "                if not(sync_sent) and not(first_line or second_line):\n",
    "                    print('sending start msg to sync device')\n",
    "                    num = b\"\".join([packIntAsLong(int(time_in_minutes*60*30 + 300))])\n",
    "                    sync_device.write(num)\n",
    "                    sync_sent = 1\n",
    "                    print(f'Sync device said: {sync_device.readline().decode(\"utf-8\")}')\n",
    "                      \n",
    "                # Write data to file\n",
    "                file.write(line)\n",
    "                file.write('\\n')\n",
    "                    \n",
    "                # Update the animator\n",
    "                thermistor_animator.update(line)\n",
    "                \n",
    "                # Test the exception handling\n",
    "#                 if trigger_started_event.is_set():\n",
    "#                     raise RuntimeError('test')\n",
    "                    \n",
    "            # After data collection finishes, close animator queue\n",
    "            print('closing animator queue')\n",
    "            thermistor_animator.close()\n",
    "            \n",
    "            # Join the Azure processes (ie block until they finish)\n",
    "            if trigger_started_event.is_set():\n",
    "                print('joining az processes')\n",
    "                exit_codes = [p.join() for p in record_processes.values() if p.is_alive()]\n",
    "            \n",
    "            # Sync device will finish on its own, but can just stop it here for convenience\n",
    "#             print('Stopping sync device')\n",
    "#             response = interrupt_sync_device(sync_device=sync_device)\n",
    "        \n",
    "            print('Done with main loop')\n",
    "            \n",
    "# Catch unexpected errors            \n",
    "except:\n",
    "    print('Exception')\n",
    "    stop_azures(trigger_started_event, interrupt_queues, sync_device_port)\n",
    "    \n",
    "    # Stop the animator process\n",
    "    print('Stopping animator')\n",
    "    thermistor_animator.close()\n",
    "    raise\n",
    "    \n",
    "finally:\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5ad21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e6deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7d2e59c",
   "metadata": {},
   "source": [
    "#### DEBUG\n",
    "* \"Cannot start process twice\" --> re-run the cell where you create the Azure processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc2f6f",
   "metadata": {},
   "source": [
    "#### DEBUG: Unfreeze Azures\n",
    "Run this to send a short pulse of triggers via the syncing device to unfreeze the Azures, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d243ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 sync pulses started!\\r\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unfreeze_azures(sync_device_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e19384",
   "metadata": {},
   "source": [
    "#### DEBUG: Stop Azures\n",
    "Run this to interrupt the Azures if they're running (eg because you unfroze them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in interrupt_queues.values(): q.put(tuple())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badbe0e",
   "metadata": {},
   "source": [
    "## Post-experiment summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74083de2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(glob.glob(os.path.join(path, '*.txt'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74dd29a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therm over: 0\n",
      "Therm under: 29038\n",
      "Time elapsed since start: 5.0 minutes\n"
     ]
    }
   ],
   "source": [
    "therm_over_thresh_count = ((data.therm > 900) & (data.dac<=0.1)).sum()\n",
    "therm_under_thresh_count = ((data.therm < 200) & (data.dac >= 3.25)).sum()\n",
    "print(f'Therm over: {therm_over_thresh_count}')\n",
    "print(f'Therm under: {therm_under_thresh_count}')\n",
    "print(f'Time elapsed since start: {(dt.datetime.now() - start_time).seconds/60:0.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417facc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bd53c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
